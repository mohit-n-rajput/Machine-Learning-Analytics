{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a03add6",
   "metadata": {},
   "source": [
    "# 5 - Merge Datasets\n",
    "\n",
    "Merging datasets is a very common practice to enrich or validate the values we have. It's easy to do but it's better used when done practically.\n",
    "\n",
    "\n",
    "In *4 - Cleaning Real Data* we used data from [hoopshype.com](hoopshype.com) that included Actual Salaries and Adjusted Salaries. In this one, we're going to create our own Adjusted Salaries using the dataset from *Appendix B - Inflation Rate Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520356b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = pathlib.Path().resolve()\n",
    "COURSES_DIR = BASE_DIR / 'course'\n",
    "APPENDIX_DIR = BASE_DIR / 'appendix'\n",
    "DATASET_PATH = BASE_DIR / 'datasets'\n",
    "SAMPLES_DIR = BASE_DIR / 'samples'\n",
    "INPUT_PATH = SAMPLES_DIR / '4-player-salaries-cleaned.csv'\n",
    "INFLATION_DATA_PATH = DATASET_PATH / 'inflation-rate.csv'\n",
    "print(f'Dataset *{INPUT_PATH.name}* exists:', INPUT_PATH.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af83091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset from 4 - Cleaning Real Data\n",
    "df = pd.read_csv(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4104781",
   "metadata": {},
   "source": [
    "Going forward, we are going to be doing a lot of analysis in 2020 dollars (2020 has the most up to date data as of October 2021).\n",
    "\n",
    "We're going to assume a few things about this scraped data:\n",
    "- Player names are correct (`player` column)\n",
    "- Salary (`salary` column) listed is their actual salary\n",
    "- Start Year is accurate (`year_start` column)\n",
    "\n",
    "Given these assumptions, we're going to create our own Adjust Salary column to illustrate how to merge data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa64ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation_df = pd.read_csv(INFLATION_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08375f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f3176c",
   "metadata": {},
   "source": [
    "*Appendix B - Inflation Rate Dataset* shows exactly where and how the dataset for `inflation_df` is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a310a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d423b23",
   "metadata": {},
   "source": [
    "Typically, the DataFrame index is auto-incrementing integers (0, 1, 2, 3, 4, ...) but it can be a time series index (ie based in dates).\n",
    "\n",
    "Setting our index to a date-like string (ie `YYYY-MM-DD`) will result in time series data.\n",
    "\n",
    "The nice thing about this is we can take a slice this data in a cool way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b14d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start = 2000\n",
    "year_end = 2005\n",
    "inflation_df[f\"{year_start}\": f\"{year_end}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628cdfaa",
   "metadata": {},
   "source": [
    "Now we see a subset of our dataset. You can treat this as a new dataframe if you need or we can use it when enriching our data. We're not going to use this type of slicing in this guide but it is nice to see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009773cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start = 2000\n",
    "year_end = 2001\n",
    "inflation_df[f\"{year_start}\": f\"{year_end}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91567b12",
   "metadata": {},
   "source": [
    "This slice should help show us something interesting: for the `year_start` and `year_end` we choose, it has 2 new values that are related both the `inflation_rate_percent` and `multiplier`.\n",
    "\n",
    "Now we *can* use an apply here to enrich our data:\n",
    "```python\n",
    "def merge_data_via_lookup(row):\n",
    "    year_start = row['year_start']\n",
    "    year_end = row['year_end']\n",
    "    new_data = inflation_df[f\"{year_start}\": f\"{year_end}\"]\n",
    "    row['multiplier'] = new_data['multiplier'].values[0]\n",
    "    return row\n",
    "    \n",
    "df.apply(merge_data_via_lookup, axis=1)\n",
    "```\n",
    "\n",
    "Technically speaking, this would work but it's not efficient and it can lead to confusion. Let's use the built-in `merge` function instead.\n",
    "\n",
    "Since `year_start` from `df` and the index (ie the `date` column) on `inflation_df` are correlated let's try a merge:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30a745",
   "metadata": {},
   "source": [
    "First, let's move the date column out of the index in `inflation_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a4dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation_df.reset_index(inplace=True, drop=False)\n",
    "inflation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea042bf",
   "metadata": {},
   "source": [
    "In this case, `reset_index` will preserve the original index (`date`) as a new column because of `drop=False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f5664",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df.merge(inflation_df, left_on=\"year_start\", right_on=\"date\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00908037",
   "metadata": {},
   "source": [
    "This merge failed because the data types do not match up. `year_start` is an integer and `date` is an object. Let's change that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f90a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['date'] = pd.to_datetime(df['year_start'])\n",
    "df['date'] = df['year_start'].apply(lambda x: datetime.datetime.strptime(f\"{x}-12-31\", \"%Y-%m-%d\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523cd4f1",
   "metadata": {},
   "source": [
    "Above I used `f\"{x}-12-31\"` to match how the `inflation_df` represents the date for the year (as opposed to the start of the year `f\"{x}-01-01\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c47b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation_df['date'] = inflation_df['date'].apply(lambda x: datetime.datetime.strptime(f\"{x}\", \"%Y-%m-%d\"))\n",
    "inflation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inflation_df['date'].dtype, df['date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628999f9",
   "metadata": {},
   "source": [
    "Now, `inflation_df['date']` and `df['date']` have the same data type, we can use `merge` on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db43fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df.merge(inflation_df, left_on=\"date\", right_on='date')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0c5d5",
   "metadata": {},
   "source": [
    "A merge is a fast way to enrich our data based on corresponding values in two dataframes. The reason we do this is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04463e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['adj_salary_audit'] = merged_df['salary'] * merged_df['multiplier']\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d52fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['audit_delta'] = merged_df['adj_salary_audit'] - merged_df['adj_salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf29124",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_adjusted = merged_df['adj_salary'].sum()\n",
    "total_adjusted_usd = utils.float_to_dollars(total_adjusted)\n",
    "total_adjusted_audit = merged_df['adj_salary_audit'].sum()\n",
    "total_adjusted_audit_usd = utils.float_to_dollars(total_adjusted_audit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab1fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_delta_sum = utils.float_to_dollars(merged_df['audit_delta'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_perc = ((total_adjusted_audit - total_adjusted) / total_adjusted_audit) * 100\n",
    "print(f\"Difference between our internal audit and their numbers is {difference_perc:.4f}% which totals to {audit_delta_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65077dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_perc = ((total_adjusted_audit - total_adjusted) / total_adjusted_audit) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bd25ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Adjusted Salary (usd)\", total_adjusted_usd)\n",
    "print(\"Total Adjusted Salary Audit (usd)\", total_adjusted_audit_usd)\n",
    "\n",
    "print(\"Delta Total\", audit_delta_sum)\n",
    "print(f\"Detla Percent Difference {difference_perc:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cb52b3",
   "metadata": {},
   "source": [
    "This shows us that our adjusted salary number is about $410 million higher but that's under 1% difference. \n",
    "\n",
    "Since this data is good enough for future pandas lessons,  we're not going to dig any deeper in improving the adjusted salaries. But there's a few questions that come to mind on how we could do it:\n",
    "\n",
    "- With this data, we used `year_start` and not `year_end` for our inflation rate multiplier. Perhaps `year_end` would yield closer results.\n",
    "- The source datasets might *both* be incorrect; how would we change this?\n",
    "- Does over `$410 million+` skew future results given total sum is over `$68 billion+`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to samples dir\n",
    "\n",
    "# merged_df.to_csv('samples/5-player-adj-salaries-audit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1e7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
