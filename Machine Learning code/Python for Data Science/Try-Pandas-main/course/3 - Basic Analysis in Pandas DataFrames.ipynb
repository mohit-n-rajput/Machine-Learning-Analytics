{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-15d3f3d1-7d9d-48b0-9022-0136024f5fa7",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "source": [
    "# 3 - Basic Analysis in Pandas DataFrames\n",
    "\n",
    "At this point, we've only be working with auto-generated data. Analyzing auto-generate data is a lot like running on a treadmill; no matter how hard to you try you'll always be stuck in the same place(s).\n",
    "\n",
    "I use auto-generated data to show you some of the fundamentals of Pandas. In the next one, we'll go into real data from NBA.com. In this one, we'll cover how to do some basic analysis on your data by using a few built-in methods that Pandas offers.\n",
    "\n",
    "Let's start by importing our sample data from `2 - Cleaning Data with Python & Pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# utils.py was created by us\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sample data\n",
    "df = pd.read_csv(\"samples/2.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Are you missing the sample data? Be sure to [launched this code on Deepnote](https://deepnote.com/launch?url=https://github.com/codingforentrepreneurs/Try-Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Data\n",
    "Let's take a basic look at how we can analyze this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()[['name', 'salary_as_float']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command does 2 things: copies the dataframe `df` and selects only some of the columns (in this case `name` and `salary_as_float`. Creating a copy means we won't accidentally modify a previous dataframe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `.shape` will give us the size of our table in the layout (`row_length`, `column_length`).  This `.shape` call matches closely with `numpy`. Something we'll have to revisit another time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = df2.shape[0]\n",
    "n_columns = df2.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_salary = df2['salary_as_float'].mean()\n",
    "most_common_salary = df2['salary_as_float'].mode() # returns a series\n",
    "top_salary = df2['salary_as_float'].max()\n",
    "bottom_salary = df2['salary_as_float'].min()\n",
    "\n",
    "print(\"Average Salary\\t\\t\\t\", utils.float_to_dollars(avg_salary))\n",
    "\n",
    "print(\"Top Salary\\t\\t\\t\", utils.float_to_dollars(top_salary))\n",
    "\n",
    "print(\"Bottom Salary\\t\\t\\t\", utils.float_to_dollars(bottom_salary))\n",
    "\n",
    "print(\"Top 3 Most Common Salaries\\t\", \", \".join(most_common_salary.apply(utils.float_to_dollars).values[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "df3['salary_normalized'] = (df3['salary_as_float'] - df3['salary_as_float'].min()) / (df3['salary_as_float'].max() - df3['salary_as_float'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing data is incredibly common. It convers a set of data (in this case `df['salary_as_float']`) and convers all numbers to be within the range of `0` and `1`. Data normalization is a common pre-processing practice when performing machine learning. We're going to use this normalized data as a way to parse our groups based on percentage values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_salary(val):\n",
    "    # in the future, this will be stored in\n",
    "    # utils.py in the courses/ directory\n",
    "    if val > .95:\n",
    "        return 'top'\n",
    "    elif val < .95 and val > .50:\n",
    "        return 'mid'\n",
    "    return 'low'\n",
    "\n",
    "df3['salary_group'] = df3['salary_normalized'].apply(group_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['salary_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.groupby('salary_group')['salary_group'].value_counts().plot(kind='bar', title='People in Group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the chart, the distribution of data falls into 3 categories based on arbitrary splitting done in the `group_salary` method above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_group = df3[['salary_as_float','salary_group']].groupby('salary_group').agg([np.sum])\n",
    "sal_group.plot(kind = \"bar\", legend = True, title='Average Salary per Group (Normalized)', color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart shows the sum total salary of each group. With Random data, this is not that interesting because there's nothing to be learned from it. With our NBA dataset, it's this chart may look vastly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e609e7b1-ff5b-43c7-8bff-b115fd3b7749",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
